---
title: "Mini-project"
author: "Katelyn Brown"
date: "2/10/2022"
output: pdf_document
---
# Unsupervised Learning Analysis of Human Cancer Cells

Load the Wisconsin cancer data.

```{r}
fna.data <- "WisconsinCancer.csv"
wisc.df <- read.csv(fna.data, row.names = 1)
#Check data set to make sure it was read correctly
head(wisc.df)
dim(wisc.df)
```

Remove first column of cancer diagnosis.

```{r}
wisc.data <- wisc.df[,-1]
```

Create diagnosis vector to save for later.

```{r}
diagnosis <- as.factor(wisc.df$diagnosis)
diagnosis
```

> Q1. How many observations are in this dataset?

```{r}
nrow(wisc.df)
```

There are 569 observations in the dataset, meaning 569 patients.

How many columns (ie. variables?)

```{r}
ncol(wisc.df)
```

There are 31 variables.

>Q2. How many observations have a malignant diagnosis?

```{r}
# Table() summarizes the dataset/vector
table(diagnosis)
```

212 patients have a malignant diagnosis.

> Q3. How many variables/features are suffixed with `_mean`?

```{r}
# Get where the column are stored
colnames(wisc.df)
# Where the matches are
grep("_mean", colnames(wisc.df))
# Find number of columns with `_mean`
length(grep("_mean", colnames(wisc.df)))
```

There are 10 variables with `_mean`.

## Use Principal Component Analysis (PCA)

Check column means and standard deviations.

```{r}
colMeans(wisc.data)
apply(wisc.data, 2, sd)
```

Perform PCA on dataset.

```{r}
wisc.pr <- prcomp(wisc.data, scale = TRUE)
# Check summary of PCA
summary(wisc.pr)
```

> Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?

44.27% of the original variance is captured by PC1.

> Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?

3 PCs are required to describe at least 70% of the original variance.

> Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

7 PCs are required to describe at least 90% of the original variance.

Plot PCA results.

Now I will make my main result: the "PCA plot" aka "score plot", "PC1 vs PC2 plot"

```{r}
# x: patients
plot(wisc.pr$x[,1:2], col = diagnosis)
```

Complete plots from workbook.

```{r}
biplot(wisc.pr)
```

> Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?

This plot is very difficult to understand because of the large cluster in the center of the plot and the amount of data. What stands out is the large bulk of observations being clustered in the center of the plot.

> Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,3], col = diagnosis, xlab = "PC1", ylab = "PC3")
```

The plot comparing PC1 and PC3 had less defining groups compared to PC1 and PC2, indicating that PC1 and PC2 might be a better pair for analysis than PC1 and PC3.

Use ggplot to make more pleasing plot.

```{r}
# Load ggplot
library(ggplot2)
# Make data frame for ggplot
df <- as.data.frame(wisc.pr$x)
df$diagnosis <- diagnosis
# Make scatter plot
ggplot(df) + aes(PC1, PC2, col = diagnosis) + geom_point()
```

Calculate variance of each component.

```{r}
pr.var <- wisc.pr$sdev^2
head(pr.var)
```

Find variance explained by each PC.

```{r}
pve <- pr.var / 30
pve
```

Plot pve.

```{r}
plot(pve, xlab = "Principal Component", ylab = "Proportion of Variance Explained", ylim = c(0,1), type = "o")
```

Make another scree plot.

```{r}
barplot(pve, ylab = "Percent of Variance Explained", names.arg = paste0("PC", 1:length(pve)), las = 2, axes = FALSE)
axis(2, at = pve, labels = round(pve, 2)*100)
```

> Q9.  For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?

```{r}
wisc.pr$rotation[,1]
```

The component of the loading vector for concave.points_mean is -0.26085.

> Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?

The minimum number of principal components required to explain 80% of the variance are 5.

## Hierarchial Clustering

First, try clustering the raw data.

```{r}
hc <- hclust(dist(wisc.data))
plot(hc)
```

Scale the data.

```{r}
data.scaled <- scale(wisc.data)
# Find distance between scaled data
data.dist <- dist(data.scaled)
wisc.hclust <- hclust(data.dist, method = "complete")
```

> Q11. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?

```{r}
plot(wisc.hclust)
table(cutree(wisc.hclust, h = 20))
abline(h = 20, col = "red", lty = 2)
```

Choose number of clusters with cutree().

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, k = 4)
table(wisc.hclust.clusters, diagnosis)
```

> Q12. Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10?

```{r}
# Make table with 2 clusters
table(cutree(wisc.hclust, k = 2), diagnosis)
# Make table with 10 clusters
table(cutree(wisc.hclust, k = 10), diagnosis)
# Make table with 6 clusters
table(cutree(wisc.hclust, k = 6), diagnosis)
```

Cutting the tree into 2 clusters provided a worse cluster vs diagnosis match compared to 4, and cutting the tree into 10 clusters provided a slightly better cluster vs diagnosis match. However, using 6 clusters provided a better cluster vs diagnosis match.

> Q13. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.

```{r}
wisc.hclust.single <- hclust(data.dist, method = "single")
plot(wisc.hclust.single)
wisc.hclust.average <- hclust(data.dist, method = "average")
plot(wisc.hclust.average)
wisc.hclust.ward.D2 <- hclust(data.dist, method = "ward.D2")
plot(wisc.hclust.ward.D2)
```
The "ward.D2" clustering  method provided the best results for the data.dist dataset, because it separated them into two visually even clusters frm the beginning, then made more complicated clusters, whereas the other data clustering methods separated them less evenly and discretely.

## K-means clustering

Compare results from hierarchical clustering to k-means clustering.

```{r}
# Make k-means model of wisc.data with 2 centers, and 20 repeats
wisc.km <- kmeans(wisc.data, centers = 2, nstart = 20)
table(wisc.km$cluster, diagnosis)
```

> Q14. How well does k-means separate the two diagnoses? How does it compare to your hclust results?

K-means clustering did a good job at separating the two diagnoses. It was able to identify most of the malignant diagnoses with only 1 "false positive." However, there were 82 "false negatives" in the first cluster. K-means clustering was slightly less effective than hclust.

```{r}
# Compare k-means to hclust
table(wisc.km$cluster, wisc.hclust.clusters)
```

## Combine methods

Combine methods to be more useful. Take PCA results and apply clustering to them.

```{r}
pcdist <- dist(wisc.pr$x[,1:3])
wisc.pr.hclust <- hclust(pcdist, method = "ward.D2")
plot(wisc.pr.hclust)
```

Use cutree() to find membership vector.

```{r}
grps <- cutree(wisc.pr.hclust, k = 2)
plot(wisc.pr$x[,1:2], col = grps)
```

Make plot based on diagnosis to compare with grps.

```{r}
plot(wisc.pr$x[,1:2], col = diagnosis)
```

Change the colors of the plots to coordinate colors with diagnoses.

```{r}
g <- as.factor(grps)
levels(g)
g <- relevel(g, 2)
levels (g)
# Plot with reordered factor
plot(wisc.pr$x[,1:2], col = g)
```

> Q15. How well do the clusters agree with the expert M/B values?

```{r}
table(diagnosis)
table(grps)
table(diagnosis, grps)
```

The clusters agree with the expert M/B values fairly well, with only a total of 24 "false positives" and 33 "false negatives."

> Q16. How well do the k-means and hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses?

```{r}
table(wisc.km$cluster, diagnosis)
table(wisc.hclust.clusters, diagnosis)
```

Both k-means and hierarchical clustering do a good job at separating diagnoses before PCA, however, PCA does the best job at clustering when comparing all three methods, based on the visual number of "false" results.

> Q17. Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?

```{r}
# Sensitivity
km.sensitivity <- 130/(130 + 82)
km.sensitivity
hclust.sensitivity <- 165/(165 + 5 + 40 + 2)
hclust.sensitivity
pca.sensitivity <- 179/(179 + 33)
pca.sensitivity
```

PCA analysis has the highest sensitivity, with 0.844, compared to 0.613 and 0.778.

```{r}
#Specificity
km.specificity <- 356/(356 + 82)
km.specificity
hclust.specificity <- (343)/(343 + 5 + 40 + 2)
hclust.specificity
pca.specificity <- 333/(333 + 33)
pca.specificity
```

PCA analysis has the highest specificity, with 0.910, compared to 0.813 and 0.880.

## Prediction

```{r}
# Load new data set
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata = new)
npc
```

```{r}
# Plot new data
plot(wisc.pr$x[,1:2], col = g)
points(npc[,1], npc[,2], col = "blue", pch = 16, cex = 3)
text(npc[,1], npc[,2], c(1,2), col = "white")
```

> Q18. Which of these new patients should we prioritize for follow up based on your results?

We should prioritize patient 2, because their results fall into the red cluster, meaning this cluster has the majority of the malignant diagnoses, so patient 2 is more likely predicted to be malignant, based on the PCA data.